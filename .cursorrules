# CARTHORSE Development Safety Rules
# This file defines safety constraints for AI-assisted development

## üîí CRITICAL SECURITY RULE - NO PII OR SECRETS

### NEVER COMMIT PII OR SECRETS
- **NEVER** include PII (Personally Identifiable Information) in code or configs
- **NEVER** include API keys, passwords, tokens, or secrets in tracked files
- **NEVER** commit database credentials, connection strings, or authentication data
- **NEVER** include user data, email addresses, phone numbers, or personal information
- **NEVER** commit environment files (.env) that contain secrets

### SECURE PATTERNS
- ‚úÖ Use `.env` files (gitignored) for all secrets and credentials
- ‚úÖ Use environment variables for sensitive configuration
- ‚úÖ Use placeholder values in tracked configs (e.g., `YOUR_API_KEY_HERE`)
- ‚úÖ Use `env.example` for showing required environment variables
- ‚úÖ Use secure credential management for production

### FORBIDDEN IN TRACKED FILES
```bash
# ‚ùå NEVER do this - secrets in tracked files
API_KEY=sk-1234567890abcdef
DATABASE_PASSWORD=mysecretpassword
USER_EMAIL=user@example.com

# ‚úÖ SAFE - use .env (gitignored) or placeholders
API_KEY=YOUR_API_KEY_HERE
DATABASE_PASSWORD=YOUR_PASSWORD_HERE
USER_EMAIL=YOUR_EMAIL_HERE
```

### SECURITY VALIDATION
Before committing any changes, verify:
- [ ] No API keys or secrets in tracked files
- [ ] No PII or personal information in code
- [ ] No database credentials in tracked configs
- [ ] All secrets are in `.env` files (gitignored)
- [ ] Placeholder values used in examples

## üö® PRODUCTION DATABASE PROTECTION

### NEVER MODIFY PRODUCTION DATABASE
- **NEVER** run commands that modify `trail_master_db` (production database)
- **NEVER** drop, truncate, or alter production tables
- **NEVER** insert, update, or delete data in production
- **NEVER** run migrations against production database
- **NEVER** use `--replace` or destructive flags on production data

### SAFE DATABASE OPERATIONS
- ‚úÖ Use `trail_master_db_test` for testing and development
- ‚úÖ Read-only queries on production are allowed for analysis
- ‚úÖ Export operations that create new files are safe
- ‚úÖ Test database operations are encouraged

### ENVIRONMENT SAFETY
- Always check `PGDATABASE` environment variable before database operations
- If `PGDATABASE=trail_master_db`, immediately stop and ask for confirmation
- Prefer `PGDATABASE=trail_master_db_test` for development work
- Use `NODE_ENV=test` when running tests

### COMMAND SAFETY PATTERNS
```bash
# ‚ùå DANGEROUS - Never do this
PGDATABASE=trail_master_db psql -c "DROP TABLE trails;"

# ‚úÖ SAFE - Use test database
PGDATABASE=trail_master_db_test psql -c "SELECT COUNT(*) FROM trails;"
```

## üîß DEVELOPMENT GUIDELINES

### Database Operations
- Always use test database for development
- Create test data using `create_test_database.sh` script
- Run tests with proper environment variables
- Export to new files, never overwrite production exports

### Code Changes
- Test all database operations in test environment first
- Use staging schemas for complex operations
- Validate data integrity before any production-like operations
- Keep production database read-only during development

### Testing
- Run unit tests with test database
- Use mock data when possible
- Validate export functionality with test data
- Never test against production data

## üö´ FORBIDDEN OPERATIONS

### Database Commands
- `DROP DATABASE trail_master_db`
- `TRUNCATE TABLE trails`
- `DELETE FROM trails`
- `ALTER TABLE trails`
- Any destructive operations on production

### Environment Variables
- Setting `PGDATABASE=trail_master_db` for write operations
- Using production credentials for development
- Running migrations against production

### File Operations
- Overwriting production export files
- Modifying production backup files
- Deleting production data files

## ‚úÖ SAFE OPERATIONS

### Allowed Commands
- `SELECT` queries on production (read-only)
- Creating test databases
- Running tests with test data
- Exporting to new files
- Development with test environment

### Safe Patterns
```bash
# Safe development workflow
PGDATABASE=trail_master_db_test npm test
PGDATABASE=trail_master_db_test npx ts-node src/cli/export.ts --region boulder --out test-output.db
```

## üÜò EMERGENCY PROCEDURES

If you accidentally run a command that might affect production:
1. **STOP IMMEDIATELY** - Do not run any more commands
2. **Check the command** - Verify what was actually executed
3. **Notify immediately** - Alert about the potential issue
4. **Document the incident** - Record what happened for future prevention

## üìã VALIDATION CHECKLIST

Before running any database command, verify:
- [ ] Using test database (`trail_master_db_test`)
- [ ] Command is read-only or creates new files
- [ ] No destructive operations (`DROP`, `DELETE`, `TRUNCATE`)
- [ ] Environment variables are safe
- [ ] Command has been tested in safe environment

Remember: **When in doubt, ask before proceeding with any database operation.**

## üìö WORKFLOW DOCUMENTATION

### Required Reading for New Sessions
- **ALWAYS** read the workflow documentation at the start of each session
- **PRIORITY**: Read `WORKFLOW.md` (or specified workflow document) before making any changes
- **UNDERSTAND**: The current development workflow, processes, and conventions
- **FOLLOW**: The established patterns and procedures documented in the workflow

### Workflow Integration
- Reference workflow documentation when suggesting changes
- Follow documented processes for database operations
- Use established patterns for testing and validation
- Maintain consistency with documented workflows

## üîí ADDITIONAL SAFETY MEASURES

### Environment Variable Validation
- Always check `NODE_ENV` before database operations
- Use `NODE_ENV=test` for all development work
- Validate `PGDATABASE` environment variable before any command

### Command Pre-flight Checks
Before running any database command, verify:
- [ ] Command is safe for the current environment
- [ ] No destructive operations (`DROP`, `DELETE`, `TRUNCATE`, `ALTER`)
- [ ] Using correct database (test vs production)
- [ ] Command has been tested in safe environment first

### Backup Strategy
- Always backup before major operations
- Use `--skip-backup` only for safe operations
- Keep backups in `backups/` directory with timestamps

### Testing Safety
- All tests must use `trail_master_db_test`
- Never run tests against production database
- Use mock data when possible
- Validate test environment before running tests

## üèóÔ∏è POSTGIS ARCHITECTURAL RULES

### ALWAYS USE EXISTING POSTGIS FUNCTIONS
- **NEVER** write custom intersection detection logic in application code
- **ALWAYS** use the existing PostGIS functions in `carthorse-postgis-intersection-functions.sql`
- **NEVER** reimplement spatial operations that PostGIS already provides
- **ALWAYS** leverage PostGIS spatial functions for performance and accuracy

### REQUIRED POSTGIS FUNCTIONS
- **`build_routing_nodes()`** - Use for creating routing nodes
- **`build_routing_edges()`** - Use for creating routing edges
- **`get_intersection_stats()`** - Use for validation and statistics
- **`validate_intersection_detection()`** - Use for quality assurance

### POSTGIS FUNCTION PATTERNS
```sql
-- ‚úÖ CORRECT - Use existing PostGIS functions
SELECT build_routing_nodes('staging_schema', 'trails', 2.0);
SELECT build_routing_edges('staging_schema', 'trails');
SELECT * FROM detect_trail_intersections('staging_schema.trails', 2.0);

-- ‚ùå WRONG - Don't write custom intersection logic
-- Custom JavaScript/TypeScript intersection detection
-- Manual coordinate calculations
-- Reimplementing PostGIS spatial operations
```

### SPATIAL OPERATION RULES
- **Use `ST_Node()`** for automatic intersection detection
- **Use `ST_LineMerge()`** for network topology creation
- **Use `ST_UnaryUnion()`** for geometry union operations
- **Use `ST_Collect()`** for geometry collection
- **Use `ST_Dump()`** for geometry decomposition
- **Use `ST_Force2D()`** for 2D optimization
- **Use `ST_Force3D()`** for 3D elevation preservation

### PERFORMANCE OPTIMIZATION
- **Always use 2D operations** for intersection detection (performance)
- **Preserve 3D data** for elevation information
- **Use spatial indexes** for large datasets
- **Batch operations** when possible
- **Use staging schemas** for processing

### VALIDATION REQUIREMENTS
- **Always validate** intersection detection results
- **Check node-to-trail ratios** (target: <50%)
- **Verify no self-loops** in routing edges
- **Ensure proper node types** (intersection/endpoint)
- **Validate spatial relationships** before export 

# Carthorse Spatial Code Rules

> **MANDATORY:** At the start of every AI or code review session, you must complete the [Spatial Code Checklist](WORKFLOW.md#carthorse-ai-session-spatial-code-checklist) in WORKFLOW.md.

## Native SQL Enforcement

- **ALWAYS** use native PostGIS or SpatiaLite SQL functions for all spatial operations (intersection, node/edge detection, splitting, etc.).
- **NEVER** implement custom geometry, intersection, or distance logic in JavaScript, TypeScript, or Python.
- **ALWAYS** use SQL functions such as: `ST_Intersects`, `ST_Intersection`, `ST_Node`, `ST_Split`, `ST_DWithin`, `ST_Union`, etc.
- **NEVER** loop over trail coordinates in application code to detect intersections or split lines.
- **ALWAYS** document any new SQL queries added for spatial processing.

## Code Review Checklist

- [ ] All intersection, node, and edge detection is performed in SQL, not JS/TS/Python.
- [ ] No custom distance or geometry logic in application code.
- [ ] All new spatial queries use PostGIS/SpatiaLite functions.
- [ ] All scripts for node/edge export reference SQL, not custom code.
- [ ] All spatial logic is tested with real region data.

## AI Session Instructions

- **ALWAYS** check for any custom geometry or intersection logic in JS/TS/Python.
- **ALWAYS** review all scripts and pipeline steps for use of native SQL.
- **ALWAYS** flag any code that does not use SQL for spatial operations.
- **ALWAYS** suggest refactoring to SQL if any custom logic is found.
- **ALWAYS** confirm that all node/edge/intersection detection is done in SQL. 

## Test User Safety Rule
- All test code and test database operations must use the 'tester' user.
- The 'tester' user must never exist in production.
- This is a safety requirement to prevent accidental destructive operations in production environments. 

# Carthorse AI/Code Review Spatial Safety Addendum

## Spatial Code Safety & Implementation Rules

- ALWAYS use native PostGIS SQL for all spatial operations (intersection, node/edge detection, splitting, simplification, validation, etc.).
- NEVER implement custom geometry, intersection, or distance logic in JavaScript, TypeScript, or Python (except trivial UI/test code).
- REMOVE or REPLACE any legacy JS/TS geometry logic (e.g., parseWktCoords) with SQL equivalents.
- All orchestrator and pipeline methods must call SQL/PostGIS for spatial logic, not JS/TS.
- All spatial validation and export logic must be SQL-based.
- All spatial indexes must be created in SQL (GIST for PostGIS, RTree for SpatiaLite).
- All DB config must be centralized and test safety rules followed (test DB, test user, no prod credentials).

## Missing/Required Orchestrator Methods (must use SQL):
- buildMasterDatabase
- cleanupStaging
- calculateDistance
- calculateAdaptiveTolerance
- simplifyGeometryWithCounts
- estimateDatabaseSize

These must be (re)implemented using SQL/PostGIS, not JS/TS.

## Checklist Reference
- See docs/SPATIAL_CODE_AUDIT_CHECKLIST.md for the full audit and review checklist. 

# Database Reference Clarity Rule
- Always prefix any mention of a database, schema, table, or column with:
  - DB type (PostGIS/PostgreSQL, SpatiaLite/SQLite, etc.)
  - Schema name (e.g., public, staging_boulder_...)
  - Table/column name (e.g., routing_edges.geometry)
- Avoid ambiguous references like 'the database' or 'the table'.
- Example: 'PostGIS (schema: staging_boulder_1753305242153): routing_edges.geometry' 

# Carthorse Project File Organization Rule

- All scripts, code, and documentation files **must** be placed in their respective subfolders (e.g., src/, scripts/, docs/, sql/, tools/, etc.).
- **Do not** place files at the project root unless they are required to be there (e.g., README.md, package.json, .gitignore, etc.) and you have explicit confirmation from the user.
- Any new files or refactored files should follow this structure for clarity and maintainability. 