# CARTHORSE Development Safety Rules
# This file defines safety constraints for AI-assisted development

## üîí CRITICAL SECURITY RULE - NO PII OR SECRETS

### NEVER COMMIT PII OR SECRETS
- **NEVER** include PII (Personally Identifiable Information) in code or configs
- **NEVER** include API keys, passwords, tokens, or secrets in tracked files
- **NEVER** commit database credentials, connection strings, or authentication data
- **NEVER** include user data, email addresses, phone numbers, or personal information
- **NEVER** commit environment files (.env) that contain secrets

### SECURE PATTERNS
- ‚úÖ Use `.env` files (gitignored) for all secrets and credentials
- ‚úÖ Use environment variables for sensitive configuration
- ‚úÖ Use placeholder values in tracked configs (e.g., `YOUR_API_KEY_HERE`)
- ‚úÖ Use `env.example` for showing required environment variables
- ‚úÖ Use secure credential management for production

### FORBIDDEN IN TRACKED FILES
```bash
# ‚ùå NEVER do this - secrets in tracked files
API_KEY=sk-1234567890abcdef
DATABASE_PASSWORD=mysecretpassword
USER_EMAIL=user@example.com

# ‚úÖ SAFE - use .env (gitignored) or placeholders
API_KEY=YOUR_API_KEY_HERE
DATABASE_PASSWORD=YOUR_PASSWORD_HERE
USER_EMAIL=YOUR_EMAIL_HERE
```

### SECURITY VALIDATION
Before committing any changes, verify:
- [ ] No API keys or secrets in tracked files
- [ ] No PII or personal information in code
- [ ] No database credentials in tracked configs
- [ ] All secrets are in `.env` files (gitignored)
- [ ] Placeholder values used in examples

## üö® PRODUCTION DATABASE PROTECTION

### NEVER MODIFY PRODUCTION DATABASE
- **NEVER** run commands that modify `trail_master_db` (production database)
- **NEVER** drop, truncate, or alter production tables
- **NEVER** insert, update, or delete data in production
- **NEVER** run migrations against production database
- **NEVER** use `--replace` or destructive flags on production data

### SAFE DATABASE OPERATIONS
- ‚úÖ Use `trail_master_db_test` for testing and development
- ‚úÖ Read-only queries on production are allowed for analysis
- ‚úÖ Export operations that create new files are safe
- ‚úÖ Test database operations are encouraged

### ENVIRONMENT SAFETY
- Always check `PGDATABASE` environment variable before database operations
- If `PGDATABASE=trail_master_db`, immediately stop and ask for confirmation
- Prefer `PGDATABASE=trail_master_db_test` for development work
- Use `NODE_ENV=test` when running tests

### COMMAND SAFETY PATTERNS
```bash
# ‚ùå DANGEROUS - Never do this
PGDATABASE=trail_master_db psql -c "DROP TABLE trails;"

# ‚úÖ SAFE - Use test database
PGDATABASE=trail_master_db_test psql -c "SELECT COUNT(*) FROM trails;"
```

## üîß DEVELOPMENT GUIDELINES

### Database Operations
- Always use test database for development
- Create test data using `create_test_database.sh` script
- Run tests with proper environment variables
- Export to new files, never overwrite production exports

### Code Changes
- Test all database operations in test environment first
- Use staging schemas for complex operations
- Validate data integrity before any production-like operations
- Keep production database read-only during development

### Testing
- Run unit tests with test database
- Use mock data when possible
- Validate export functionality with test data
- Never test against production data

## üö´ FORBIDDEN OPERATIONS

### Database Commands
- `DROP DATABASE trail_master_db`
- `TRUNCATE TABLE trails`
- `DELETE FROM trails`
- `ALTER TABLE trails`
- Any destructive operations on production

### Environment Variables
- Setting `PGDATABASE=trail_master_db` for write operations
- Using production credentials for development
- Running migrations against production

### File Operations
- Overwriting production export files
- Modifying production backup files
- Deleting production data files

## ‚úÖ SAFE OPERATIONS

### Allowed Commands
- `SELECT` queries on production (read-only)
- Creating test databases
- Running tests with test data
- Exporting to new files
- Development with test environment

### Safe Patterns
```bash
# Safe development workflow
PGDATABASE=trail_master_db_test npm test
PGDATABASE=trail_master_db_test npx ts-node src/cli/export.ts --region boulder --out test-output.db
```

## üÜò EMERGENCY PROCEDURES

If you accidentally run a command that might affect production:
1. **STOP IMMEDIATELY** - Do not run any more commands
2. **Check the command** - Verify what was actually executed
3. **Notify immediately** - Alert about the potential issue
4. **Document the incident** - Record what happened for future prevention

## üìã VALIDATION CHECKLIST

Before running any database command, verify:
- [ ] Using test database (`trail_master_db_test`)
- [ ] Command is read-only or creates new files
- [ ] No destructive operations (`DROP`, `DELETE`, `TRUNCATE`)
- [ ] Environment variables are safe
- [ ] Command has been tested in safe environment

Remember: **When in doubt, ask before proceeding with any database operation.**

## üìö WORKFLOW DOCUMENTATION

### Required Reading for New Sessions
- **ALWAYS** read the workflow documentation at the start of each session
- **PRIORITY**: Read `WORKFLOW.md` (or specified workflow document) before making any changes
- **UNDERSTAND**: The current development workflow, processes, and conventions
- **FOLLOW**: The established patterns and procedures documented in the workflow

### Workflow Integration
- Reference workflow documentation when suggesting changes
- Follow documented processes for database operations
- Use established patterns for testing and validation
- Maintain consistency with documented workflows

## üîí ADDITIONAL SAFETY MEASURES

### Environment Variable Validation
- Always check `NODE_ENV` before database operations
- Use `NODE_ENV=test` for all development work
- Validate `PGDATABASE` environment variable before any command

### Command Pre-flight Checks
Before running any database command, verify:
- [ ] Command is safe for the current environment
- [ ] No destructive operations (`DROP`, `DELETE`, `TRUNCATE`, `ALTER`)
- [ ] Using correct database (test vs production)
- [ ] Command has been tested in safe environment first

### Backup Strategy
- Always backup before major operations
- Use `--skip-backup` only for safe operations
- Keep backups in `backups/` directory with timestamps

### Testing Safety
- All tests must use `trail_master_db_test`
- Never run tests against production database
- Use mock data when possible
- Validate test environment before running tests

## üèóÔ∏è POSTGIS ARCHITECTURAL RULES

### ALWAYS USE EXISTING POSTGIS FUNCTIONS
- **NEVER** write custom intersection detection logic in application code
- **ALWAYS** use the existing PostGIS functions in `carthorse-postgis-intersection-functions.sql`
- **NEVER** reimplement spatial operations that PostGIS already provides
- **ALWAYS** leverage PostGIS spatial functions for performance and accuracy

### REQUIRED POSTGIS FUNCTIONS
- **`build_routing_nodes()`** - Use for creating routing nodes
- **`build_routing_edges()`** - Use for creating routing edges
- **`get_intersection_stats()`** - Use for validation and statistics
- **`validate_intersection_detection()`** - Use for quality assurance

### POSTGIS FUNCTION PATTERNS
```sql
-- ‚úÖ CORRECT - Use existing PostGIS functions
SELECT build_routing_nodes('staging_schema', 'trails', 2.0);
SELECT build_routing_edges('staging_schema', 'trails');
SELECT * FROM detect_trail_intersections('staging_schema.trails', 2.0);

-- ‚ùå WRONG - Don't write custom intersection logic
-- Custom JavaScript/TypeScript intersection detection
-- Manual coordinate calculations
-- Reimplementing PostGIS spatial operations
```

### SPATIAL OPERATION RULES
- **Use `ST_Node()`** for automatic intersection detection
- **Use `ST_LineMerge()`** for network topology creation
- **Use `ST_UnaryUnion()`** for geometry union operations
- **Use `ST_Collect()`** for geometry collection
- **Use `ST_Dump()`** for geometry decomposition
- **Use `ST_Force2D()`** for 2D optimization
- **Use `ST_Force3D()`** for 3D elevation preservation

### PERFORMANCE OPTIMIZATION
- **Always use 2D operations** for intersection detection (performance)
- **Preserve 3D data** for elevation information
- **Use spatial indexes** for large datasets
- **Batch operations** when possible
- **Use staging schemas** for processing

### VALIDATION REQUIREMENTS
- **Always validate** intersection detection results
- **Check node-to-trail ratios** (target: <50%)
- **Verify no self-loops** in routing edges
- **Ensure proper node types** (intersection/endpoint)
- **Validate spatial relationships** before export 

# Carthorse Spatial Code Rules

> **MANDATORY:** At the start of every AI or code review session, you must complete the [Spatial Code Checklist](WORKFLOW.md#carthorse-ai-session-spatial-code-checklist) in WORKFLOW.md.

## Native SQL Enforcement

- **ALWAYS** use native PostGIS or SpatiaLite SQL functions for all spatial operations (intersection, node/edge detection, splitting, etc.).
- **NEVER** implement custom geometry, intersection, or distance logic in JavaScript, TypeScript, or Python.
- **ALWAYS** use SQL functions such as: `ST_Intersects`, `ST_Intersection`, `ST_Node`, `ST_Split`, `ST_DWithin`, `ST_Union`, etc.
- **NEVER** loop over trail coordinates in application code to detect intersections or split lines.
- **ALWAYS** document any new SQL queries added for spatial processing.

## Code Review Checklist

- [ ] All intersection, node, and edge detection is performed in SQL, not JS/TS/Python.
- [ ] No custom distance or geometry logic in application code.
- [ ] All new spatial queries use PostGIS/SpatiaLite functions.
- [ ] All scripts for node/edge export reference SQL, not custom code.
- [ ] All spatial logic is tested with real region data.

## AI Session Instructions

- **ALWAYS** check for any custom geometry or intersection logic in JS/TS/Python.
- **ALWAYS** review all scripts and pipeline steps for use of native SQL.
- **ALWAYS** flag any code that does not use SQL for spatial operations.
- **ALWAYS** suggest refactoring to SQL if any custom logic is found.
- **ALWAYS** confirm that all node/edge/intersection detection is done in SQL. 

## Test User Safety Rule
- All test code and test database operations must use the 'tester' user.
- The 'tester' user must never exist in production.
- This is a safety requirement to prevent accidental destructive operations in production environments. 

# Carthorse AI/Code Review Spatial Safety Addendum

## Spatial Code Safety & Implementation Rules

- ALWAYS use native PostGIS SQL for all spatial operations (intersection, node/edge detection, splitting, simplification, validation, etc.).
- NEVER implement custom geometry, intersection, or distance logic in JavaScript, TypeScript, or Python (except trivial UI/test code).
- REMOVE or REPLACE any legacy JS/TS geometry logic (e.g., parseWktCoords) with SQL equivalents.
- All orchestrator and pipeline methods must call SQL/PostGIS for spatial logic, not JS/TS.
- All spatial validation and export logic must be SQL-based.
- All spatial indexes must be created in SQL (GIST for PostGIS, RTree for SpatiaLite).
- All DB config must be centralized and test safety rules followed (test DB, test user, no prod credentials).

## Missing/Required Orchestrator Methods (must use SQL):
- buildMasterDatabase
- cleanupStaging
- calculateDistance
- calculateAdaptiveTolerance
- simplifyGeometryWithCounts
- estimateDatabaseSize

These must be (re)implemented using SQL/PostGIS, not JS/TS.

## Checklist Reference
- See docs/SPATIAL_CODE_AUDIT_CHECKLIST.md for the full audit and review checklist. 

# Database Reference Clarity Rule
- Always prefix any mention of a database, schema, table, or column with:
  - DB type (PostGIS/PostgreSQL, SpatiaLite/SQLite, etc.)
  - Schema name (e.g., public, staging_boulder_...)
  - Table/column name (e.g., routing_edges.geometry)
- Avoid ambiguous references like 'the database' or 'the table'.
- Example: 'PostGIS (schema: staging_boulder_1753305242153): routing_edges.geometry' 

# Carthorse Project File Organization Rule

- All scripts, code, and documentation files **must** be placed in their respective subfolders (e.g., src/, scripts/, docs/, sql/, tools/, etc.).
- **Do not** place files at the project root unless they are required to be there (e.g., README.md, package.json, .gitignore, etc.) and you have explicit confirmation from the user.
- Any new files or refactored files should follow this structure for clarity and maintainability. 

# Carthorse SQLite v12 Schema Conformance Rules

## MANDATORY v12 Schema Compliance

### ALWAYS USE v12 SCHEMA
- **NEVER** use backward compatibility or schema detection logic
- **ALWAYS** use `source` and `target` columns for routing edges (v12 schema)
- **NEVER** use `from_node_id` and `to_node_id` (older schemas)
- **ALWAYS** force v12 schema creation in SQLite export code
- **NEVER** implement fallback logic for older schemas

### v12 Schema Requirements
- **routing_edges.source** - pgRouting source node ID (INTEGER NOT NULL)
- **routing_edges.target** - pgRouting target node ID (INTEGER NOT NULL)
- **routing_edges.trail_id** - Reference to original trail (TEXT)
- **routing_edges.trail_name** - Trail name (TEXT)
- **routing_edges.distance_km** - Distance in kilometers (REAL CHECK > 0)
- **routing_edges.geojson** - Geometry as GeoJSON (TEXT NOT NULL)
- **routing_edges.created_at** - Creation timestamp (DATETIME DEFAULT CURRENT_TIMESTAMP)

### FORBIDDEN PATTERNS
```typescript
// ‚ùå NEVER do this - schema detection/fallback logic
const hasSourceColumn = tableInfo.some((col: any) => col.name === 'source');
const hasFromNodeIdColumn = tableInfo.some((col: any) => col.name === 'from_node_id');
if (hasFromNodeIdColumn) {
  // Use older schema
}

// ‚ùå NEVER do this - backward compatibility
const sourceId = edge.source || edge.from_node_id;
const targetId = edge.target || edge.to_node_id;
```

### REQUIRED PATTERNS
```typescript
// ‚úÖ ALWAYS do this - v12 schema only
const insertStmt = db.prepare(`
  INSERT OR IGNORE INTO routing_edges (
    source, target, trail_id, trail_name, distance_km, geojson, created_at
  ) VALUES (?, ?, ?, ?, ?, ?, ?)
`);

// ‚úÖ ALWAYS do this - force v12 schema creation
db.exec('DROP TABLE IF EXISTS routing_edges');
db.exec(`
  CREATE TABLE IF NOT EXISTS routing_edges (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source INTEGER NOT NULL,
    target INTEGER NOT NULL,
    trail_id TEXT,
    trail_name TEXT,
    distance_km REAL CHECK(distance_km > 0),
    geojson TEXT NOT NULL,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
  )
`);
```

### CODE REVIEW CHECKLIST
- [ ] No schema detection logic in SQLite export code
- [ ] No backward compatibility or fallback patterns
- [ ] All routing edge operations use `source`/`target` columns
- [ ] Table creation forces v12 schema
- [ ] No references to `from_node_id`/`to_node_id` columns
- [ ] All indexes use v12 column names

### GREENFIELD DEVELOPMENT RULES
- This is greenfield software - no legacy compatibility needed
- Always use latest v12 schema for all new development
- Remove any existing backward compatibility code
- Force clean v12 schema creation in all export operations
- Never implement schema detection or migration logic

# Carthorse Export Target File Cleanup Rules

## MANDATORY EXPORT TARGET CLEANUP

### ALWAYS DELETE EXISTING EXPORT FILES
- **ALWAYS** delete existing SQLite database files before creating new ones
- **ALWAYS** delete related SQLite files (.db-shm, .db-wal) to ensure clean slate
- **NEVER** reuse existing database files that may have old schemas
- **ALWAYS** start with a completely clean export target

### REQUIRED CLEANUP PATTERNS
```typescript
// ‚úÖ ALWAYS do this - comprehensive cleanup
if (fs.existsSync(this.config.outputPath)) {
  console.log(`üóëÔ∏è  Deleting existing SQLite database: ${this.config.outputPath}`);
  fs.unlinkSync(this.config.outputPath);
}

// Also delete any related SQLite files (WAL, SHM)
const dbPathWithoutExt = this.config.outputPath.replace(/\.db$/, '');
const relatedFiles = [
  `${dbPathWithoutExt}.db-shm`,
  `${dbPathWithoutExt}.db-wal`,
  `${this.config.outputPath}-shm`,
  `${this.config.outputPath}-wal`
];

for (const file of relatedFiles) {
  if (fs.existsSync(file)) {
    console.log(`üóëÔ∏è  Deleting related SQLite file: ${file}`);
    fs.unlinkSync(file);
  }
}
```

### FORBIDDEN PATTERNS
```typescript
// ‚ùå NEVER do this - reusing existing files
const sqliteDb = new Database(this.config.outputPath); // Without cleanup

// ‚ùå NEVER do this - partial cleanup
if (fs.existsSync(this.config.outputPath)) {
  fs.unlinkSync(this.config.outputPath);
} // Missing related file cleanup
```

### EXPORT SAFETY CHECKLIST
- [ ] Delete main .db file if exists
- [ ] Delete .db-shm file if exists  
- [ ] Delete .db-wal file if exists
- [ ] Delete -shm file if exists
- [ ] Delete -wal file if exists
- [ ] Create new database with v12 schema
- [ ] Verify schema compliance after creation 

# Carthorse Database Schema Distinction Rules

## MANDATORY SCHEMA DISTINCTION

### TWO DISTINCT DATABASE SCHEMAS
- **PostGIS/PostgreSQL Schema**: Main database with spatial functions, staging, and processing
- **SQLite Schema**: Export target database for mobile apps and offline use

### POSTGIS SCHEMA NAMING CONVENTIONS
- **Prefix**: `postgis_` for files, `postgres_` for functions
- **Examples**: `postgis-intersection-functions.sql`, `postgres-schema.sql`
- **Tables**: `public.trails`, `staging_schema.trails`, `routing_nodes`, `routing_edges`
- **Functions**: `detect_trail_intersections()`, `build_routing_nodes()`, `copy_and_split_trails_to_staging_native()`
- **Geometry**: `GEOMETRY(LINESTRINGZ, 4326)` with 3D elevation support
- **Spatial Operations**: `ST_Node()`, `ST_Intersection()`, `ST_Force3D()`

### SQLITE SCHEMA NAMING CONVENTIONS
- **Prefix**: `sqlite_` for files and functions
- **Examples**: `sqlite-schema-v12.sql`, `sqlite-export-helpers.ts`
- **Tables**: `trails`, `routing_nodes`, `routing_edges`, `region_metadata`
- **Functions**: `createSqliteTables()`, `insertTrails()`, `insertRoutingEdges()`
- **Geometry**: `geojson TEXT NOT NULL` - all geometry as GeoJSON strings
- **Constraints**: `CHECK(distance_km > 0)`, `CHECK(elevation_gain >= 0)`

### SCHEMA-SPECIFIC PATTERNS

#### PostGIS Schema Patterns
```sql
-- ‚úÖ PostGIS: 3D geometry with elevation
CREATE TABLE trails (
  geometry GEOMETRY(LINESTRINGZ, 4326),
  elevation_gain REAL,
  elevation_loss REAL
);

-- ‚úÖ PostGIS: Spatial functions
SELECT ST_Node(geometry) FROM trails;
SELECT ST_Intersection(t1.geometry, t2.geometry) FROM trails t1, trails t2;
```

#### SQLite Schema Patterns
```sql
-- ‚úÖ SQLite: GeoJSON geometry storage
CREATE TABLE trails (
  geojson TEXT NOT NULL,
  elevation_gain REAL CHECK(elevation_gain >= 0),
  elevation_loss REAL CHECK(elevation_loss >= 0)
);

-- ‚úÖ SQLite: pgRouting optimized
CREATE TABLE routing_edges (
  source INTEGER NOT NULL,
  target INTEGER NOT NULL,
  distance_km REAL CHECK(distance_km > 0)
);
```

### DOCUMENTATION REQUIREMENTS
- **ALWAYS** specify which schema (PostGIS or SQLite) in documentation
- **ALWAYS** use schema-specific naming in code comments
- **ALWAYS** distinguish between PostGIS spatial functions and SQLite constraints
- **NEVER** use ambiguous terms like "the database" or "the schema"

### CODE REVIEW CHECKLIST
- [ ] PostGIS files use `postgis_` or `postgres_` prefixes
- [ ] SQLite files use `sqlite_` prefixes
- [ ] PostGIS functions use spatial operations (`ST_*`)
- [ ] SQLite functions use data validation (`CHECK` constraints)
- [ ] Documentation clearly specifies which schema is being discussed
- [ ] No ambiguous database references 